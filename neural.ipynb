{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The net\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./images/net.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1, Forward Propagation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by defining some hyperparameters, constants which establish the\n",
    "structure and behavior of the network and are not updated as we train.\n",
    "\n",
    "We're going to look at hours of sleep and hours of study, and predict our test score.\n",
    "\n",
    "Here X is a 3x2 matrix, and Y is 3 x 1.\n",
    "\n",
    "$3W_{11} + 5W_{21}$ per each neuron is what we want. We need to figure out\n",
    "weights for each variable, for each example we have.\n",
    "\n",
    "We can do this with matrix multiplication (always remember [http://matrixmultiplication.xyz/](http://matrixmultiplication.xyz/)).\n",
    "\n",
    "$$  \\begin{bmatrix}\n",
    "3 & 5 \\\\\n",
    "5 & 1 \\\\\n",
    "10 & 2\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "W_{11} & W_{12} & W_{13}\\\\\n",
    "W_{21} & W_{22} & W_{23}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$XW^{(1)} = Z^{(2)}$, where $Z^{(2)}$ is the activity of our second layer.\n",
    "\n",
    "$$\n",
    "Z^{(2)} = \\begin{bmatrix}\n",
    "3W_{11} + 5W_{21} & 3W_{12} + 5W_{22} & 3W_{13} + 5W_{33} \\\\\n",
    "5W_{11} + 1W_{21} & 5W_{12} + 1W_{22} & 5W_{13} + 1W_{33} \\\\\n",
    "10W_{11} + 2W_{21} & 10W_{12} + 2W_{22} & 10W_{13} + 2W_{33} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So each entry in Z is a sum of weighted inputs to each neuron. It has size 3x3:\n",
    "one row for each example, one column for each hidden unit.\n",
    "\n",
    "Next we will independently apply the activation function to each entry in Z.\n",
    "We'll use the sigmoid function, leaning on NumPy, which rather conveniently\n",
    "applies the function element-wise and returns the result with the same\n",
    "dimensions it was given.\n",
    "\n",
    "$$\n",
    "a^{(2)} = \\begin{bmatrix}\n",
    "\\sigma(3W_{11} + 5W_{21}) & \\sigma(3W_{12} + 5W_{22}) & \\sigma(3W_{13} + 5W_{33}) \\\\\n",
    "\\sigma(5W_{11} + 1W_{21}) & \\sigma(5W_{12} + 1W_{22}) & \\sigma(5W_{13} + 1W_{33}) \\\\\n",
    "\\sigma(10W_{11} + 2W_{21}) & \\sigma(10W_{12} + 2W_{22}) & \\sigma(10W_{13} + 2W_{33}) \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So we have $a^{(2)} = f(Z^{(2)})$. We'll then apply one more set of weights to\n",
    "get our final output, with dimensions 3 x 1, and then run the activation function on that too.\n",
    "\n",
    "$Z^{(3)} = a^{(2)} W^{(2)}$, and $\\hat{y} = f(Z^{(3)})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[75],\n",
      "       [82],\n",
      "       [93]])"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[3, 5],\n",
    "             [5, 1],\n",
    "             [10, 2]])\n",
    "y = np.array([[75], [82], [93]])\n",
    "\n",
    "# Normalize\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100 #Max test score is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputLayersSize = 2\n",
    "        self.outputLayersSize = 1\n",
    "        self.hiddenLayersSize = 3\n",
    "\n",
    "        self.W1 = np.random.randn(self.inputLayersSize, self.hiddenLayersSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayersSize, self.outputLayersSize)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.Z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.Z2)\n",
    "\n",
    "        self.Z3 = np.dot(self.a2, self.W2)\n",
    "\n",
    "        y_hat = self.sigmoid(self.Z3)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.09039106],\n",
      "       [0.06463066],\n",
      "       [0.06301298]])"
     ]
    }
   ],
   "source": [
    "sigmoid(1), sigmoid(np.array([-1, 0, 1])), sigmoid(np.random.randn(3, 3))\n",
    "\n",
    "NN = Neural_Network()\n",
    "y_hat = NN.forward(X)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, these results are completely terrible compared to our actual test\n",
    "scores! That is because we are using random weights. Next we need to update our weights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts 2 - 4: Gradient Descent and Back Propagation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal now is to quantify how wrong our predictions are, figure out how to\n",
    "update our weights in the right direction, and use our wrongess-quantity to\n",
    "adjust the weights by some suitable amount.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying wrongness with a loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use several measures of wrongness. For instance, we could just take\n",
    "$y - \\hat{y}$, and that would be fine. Because we're coming up with a single\n",
    "weight for all our examples, we would average this. Our loss function would thus\n",
    "be Mean Absolute Error, or MAE.\n",
    "\n",
    "However, Mean Squared Error is more commonly used, although\n",
    "[arguments for this are not perfectly convincing](https://stats.stackexchange.com/questions/470626/why-is-using-squared-error-the-standard-when-absolute-error-is-more-relevant-to). It is a little easier to do\n",
    "calculus on, and most importantly, because it is a convex function, we can be\n",
    "sure it will be defined at 0, and more extreme errors will get penalized more,\n",
    "meaning we will learn faster the wronger we are, which is nice.\n",
    "\n",
    "Mean Squared Error looks like $\\sum (y - \\hat{y})^2$, and if we divide by 2 to\n",
    "help us do calculus later it will still have all the properties we want: $J = \\sum \\frac{1}{2}\n",
    "(y - \\hat{y})^2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which way to jiggle the weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a loss function, how do we know how to improve our weights?\n",
    "Random guessing will not work, due to the curse of dimensionality. With 6\n",
    "weights, assume they might have 1000 possible values each, and we have\n",
    "$1000^{6}$ guesses to make!\n",
    "\n",
    "We could also jiggle each weight up or down a little, and see if the whole thing\n",
    "improves. That will work but be slow.\n",
    "\n",
    "Fortunately we have a better way! We want to know how our cost function J\n",
    "changes when $\\hat{y}$, or W, changes. This is a derivative! If the derivative\n",
    "is positive, we are heading in the wrong direction. We'll keep changing until\n",
    "the derivative of our loss function starts getting worse again.\n",
    "\n",
    "If we consider one weight at a time, then we want to know how J changes when\n",
    "just one weight changes, and that's a partial derivative: $\\frac{\\partial\n",
    "J}{\\partial W}$.\n",
    "\n",
    "This is one reason we chose our loss function as we did. It's convex, so we will\n",
    "always know which direction to go in. In higher dimensions, the combination of\n",
    "all these weights could get us stuck in a local minimum, but if we update our\n",
    "weights one at a time (stochastic gradient descent), we might be fine anyway.\n",
    "\n",
    "Anyway, today we will do batch gradient descent, and update them all at once,\n",
    "based on the partial derivative of each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing the Math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $W^{(1)}$ we should get:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial J}{\\partial W_{11}} & \\frac{\\partial J}{\\partial W_{12}} & \\frac{\\partial J}{\\partial W_{13}}\\\\\n",
    "\\frac{\\partial J}{\\partial W_{21}} & \\frac{\\partial J}{\\partial W_{22}} & \\frac{\\partial J}{\\partial W_{33}}\\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "And for $W^{(2)}$ we should get:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial J}{\\partial W_{11}^{(2)}} \\\\\n",
    "\\frac{\\partial J}{\\partial W_{21}^{(2)}} \\\\\n",
    "\\frac{\\partial J}{\\partial W_{31}^{(2)}}\n",
    "\\end{bmatrix}\n",
    "\n",
    "$\\frac{\\partial J}{\\partial W^{(2)}} = \\frac{\\partial \\sum \\frac{1}{2} (y -\n",
    "\\hat{y})^2}{\\partial W^{(2)}}$, since that's what J is.\n",
    "\n",
    "The sum here is adding the error from each example to create an overall cost.\n",
    "The Sum Rule, $\\frac{d}{dx}(u + v) = \\frac{du}{dx} + \\frac{dv}{dx}$, says that\n",
    "we can move the summation outside our derivative, which is handy.\n",
    "\n",
    "$\\sum \\frac{\\partial \\frac{1}{2} (y - \\hat{y})^2}{\\partial W^{(2)}}$\n",
    "\n",
    "We'll come back and add up later.\n",
    "\n",
    "Well, next we apply the power rule: $\\frac{\\partial J}{\\partial W^{(2)}} = 2 \\cdot \\frac{1}{2} (y - \\hat{y}) = (y - \\hat{y})$, and isn't that convenient.\n",
    "\n",
    "That was the outer function, now to follow the chain rule we must take the\n",
    "derivative of the inner function.\n",
    "\n",
    "A better name for back propagation might be, don't stop doing the chain rule, ever!\n",
    "\n",
    "The $y$ is a constant and goes to 0.\n",
    "\n",
    "$\\frac{\\partial J}{\\partial W^{(2)}} = (y - \\hat{y}) \\cdot - \\frac{\\partial \\hat{y}}{\\partial W^{(2)}}$\n",
    "\n",
    "However $\\hat{y}$ is itself a function, $\\hat{y} = f(z^{(3)})$, and we must apply the chain rule again.\n",
    "\n",
    "$\\frac{\\partial \\hat{y}}{\\partial W^{(2)}} = \\frac{\\partial \\hat{y}}{\\partial z^{(3)}} \\cdot \\frac{\\partial z^{(3)}}{\\partial W^{(2)}}$\n",
    "\n",
    "Meaning, again, we want the entire phrase:  \n",
    "$- (y - \\hat{y}) \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(3)}} \\cdot \\frac{\\partial z^{(3)}}{\\partial W^{(2)}}$\n",
    "\n",
    "Now, $f(z^{(3)})$ was our sigmoid function, which is $\\frac{1}{1 + e^{-z}}$.\n",
    "\n",
    "To take this derivative, rewrite as $(1 + e^{-z})^{-1}$, and apply the power\n",
    "rule to get $-(1 + e^{-z})^{-2}$, but then we must apply the product rule to get\n",
    "$-(1 + e^{-z})^{-2})(\\frac{d}{z} 1 + e^{-z})$. Which equals:\n",
    "\n",
    "$-(1 + e^{-z})^{-2})(\\frac{d}{dz}(1 + e^{-z})) = -(1 + e^{-z})^{-2})(-1)(e^{-z}))$\n",
    "\n",
    "And:\n",
    "$\\frac{e^{-z}}{(1 + e^{-z})^{2}}$. If you do a lot of algebra there, you can\n",
    "also write this as $\\sigma(x) \\cdot (1 - \\sigma(x))$.\n",
    "\n",
    "Having found $f'(z^{(3)}$, we can slot that in.\n",
    "\n",
    "$- (y - \\hat{y}) \\cdot \\frac{e^{-z}}{(1 + e^{-z})^{2}} \\cdot \\frac{\\partial z^{(3)}}{\\partial W^{(2)}}$\n",
    "\n",
    "And we just need our last term. This is how our output - the sum of the\n",
    "activated (first weights \\* inputs) multiplied by the second weights - changes as\n",
    "the second weights change.\n",
    "\n",
    "Here's the thing, z3 is a linear function with respect to the W2 weights. Their\n",
    "relationship is measured by the activations. If\n",
    "they go up, the values go up. And the derivative of a linear function - it's\n",
    "just a plain ol' slope like we learned in 5th grade. Here the slope is the\n",
    "activations, a2.\n",
    "\n",
    "(this doesn't sound right to me. We change the weights W2, surely)\n",
    "\n",
    "Our final formula:\n",
    "\n",
    "$- (y - \\hat{y}) \\cdot \\frac{e^{-z}}{(1 + e^{-z})^{2}} \\cdot a^{(2)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom Out a Bit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that calculus! We wanted to figure out how much our output depended on the\n",
    "final set of weights we applied. First we had to apply the power rule. Then, we\n",
    "figured out how much our output was changed by our sigmoid function. Then we\n",
    "multiplied by the activations.\n",
    "\n",
    "Remember we'll calculate all this by neuron, by weight. You can think about this\n",
    "as: we multiply by each activation, because that is how much they each\n",
    "proportionately contributed to the error. Crucially, this is what lets back\n",
    "propagation work its magic!\n",
    "\n",
    "**Our final formula in a nutshell**: *Multiply the size of error, by the derivative of the activation\n",
    "function, by all our examples with the weights and activation function applied.* \n",
    "\n",
    "If you do all that, you will know just how to change each weight.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiply it out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "\\end{bmatrix} - \\begin{bmatrix}\n",
    "\\hat{y}_1 \\\\\n",
    "\\hat{y}_2 \\\\\n",
    "\\hat{y}_3 \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "y_1 - \\hat{y}_1 \\\\\n",
    "y_2 - \\hat{y}_2 \\\\\n",
    "y_3 - \\hat{y}_3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "When we applied sigmoid function, we also got a 3x1 matrix, and sigmoidPrime\n",
    "will have the same shape. In other words $f'(z^{(3)}$ is also 3x1, and we can do\n",
    "element-wise multiplication.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeYs = [[1], [2], [3]]\n",
    "fakeSigPrime = [[1], [2], [3]]\n",
    "\n",
    "np.multiply(fakeYs, fakeSigPrime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The size of each error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_1 - \\hat{y}_1 \\\\\n",
    "y_2 - \\hat{y}_2 \\\\\n",
    "y_3 - \\hat{y}_3 \\\\\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "f'(z^{(3)}_1) \\\\\n",
    "f'(z^{(3)}_2) \\\\\n",
    "f'(z^{(3)}_3) \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\delta^{(3)}_1 \\\\\n",
    "\\delta^{(3)}_2 \\\\\n",
    "\\delta^{(3)}_3 \\\\\n",
    "\\end{bmatrix} = \\delta^{(3)}\n",
    "$$\n",
    "\n",
    "This is called \"the back-propagating error, $\\delta^{(3)}$.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiply together\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we want to multiply by $a^{(2)}$, $\\delta^{(3)} a^{(2)}$. However,\n",
    "we've got\n",
    "\n",
    "$$ a^{(2)} = \\begin{bmatrix}\n",
    "a_{11} & a_{12} & a_{13}\\\\\n",
    "a_{21} & a_{22} & a_{23}\\\\\n",
    "a_{31} & a_{32} & a_{33}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "These matrices don't match. You can't multiply 3x1 with 3x3.\n",
    "\n",
    "We can make it work by transposing and multiplying, which I'll assume is the\n",
    "same thing in linear algebra, or something. You can multiply 3x3 with 3x1.\n",
    "\n",
    "\\\\[\n",
    "\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{21} & a_{31}\\\\\n",
    "a_{12} & a_{22} & a_{32}\\\\\n",
    "a_{13} & a_{23} & a_{33}\\\\\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "\\delta^{(3)}_1 \\\\\n",
    "\\delta^{(3)}_2 \\\\\n",
    "\\delta^{(3)}_3 \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "a_{11} \\: \\delta^{(3)}_1 + a_{21} \\: \\delta^{(3)}_2 + a_{31} \\: \\delta^{(3)}_3 \\\\\n",
    "a_{12} \\: \\delta^{(3)}_1 + a_{22} \\: \\delta^{(3)}_2 + a_{32} \\: \\delta^{(3)}_3 \\\\\n",
    "a_{13} \\: \\delta^{(3)}_1 + a_{23} \\: \\delta^{(3)}_2 + a_{33} \\: \\delta^{(3)}_3 \\\\\n",
    "\\end{bmatrix} \n",
    "\n",
    "\\\\]\n",
    "\n",
    "And the cool thing here is that the matrix multiplication is adding up across\n",
    "our examples - there's that summation $\\Delta$ we took out earlier!\n",
    "\n",
    "You can also think of batching gradient as contributing to the overall cost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once More, with Feeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have propagated the error backward to our last set of weights, we\n",
    "need to keep going. How did our first set of weights affect the output? We will\n",
    "do the same thing, take the partial differential with respect to those weights.\n",
    "\n",
    "$\\frac{\\partial J}{\\partial W^{(1)}} = \\frac{\\partial \\sum \\frac{1}{2} (y -\n",
    "\\hat{y})^2}{\\partial W^{(1)}}$, since that's what J is.\n",
    "\n",
    "Move the summation outside: \n",
    "$\\sum \\frac{\\partial \\frac{1}{2} (y - \\hat{y})^2}{\\partial W^{(1)}}$\n",
    "\n",
    "Then $- (y - \\hat{y}) \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(3)}} \\cdot \\frac{\\partial z^{(3)}}{\\partial W^{(1)}}$\n",
    "\n",
    "Remember that $- (y - \\hat{y}) \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(3)}}$\n",
    "translates to the back-propagating error, $\\delta^{(3)}$.\n",
    "\n",
    "Now we are\n",
    "calculating the rate of change of z3 with respec to a2, $$\\frac{dz}{da_2}$$, so\n",
    "to speak. The slope here equals the weight value for that synapse.\n",
    "\n",
    "For some reason he says last time we computed the derivative with respect to the\n",
    "weights but now we are computing across the synapses.\n",
    "\n",
    "$\\delta^{(3)} \\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\frac{\\partial\n",
    "a^{(2)}}{\\partial W^{(1)}}$\n",
    "\n",
    "The slope is now equal to the weight value for this synapse, which frankly makes\n",
    "more sense than the a2 being the slope as it was last time.\n",
    "\n",
    "We'll achieve this by multiplying by the transpose:\n",
    "\n",
    "$\\delta^{(3)} (W^{(2)})^T \\frac{\\partial a^{(2)}}{\\partial W^{(1)}}$\n",
    "\n",
    "\n",
    "the last term separates into $\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\frac{\\partial z^{(2)}}{\\partial W^{(1)}}$\n",
    "\n",
    "The first part is the whole sigmoid calculation we did before and so we replace\n",
    "with $f'(z^{(2)})$.\n",
    "\n",
    "The second part works out as it did last time with $a^{(2)}$, but with X this time.\n",
    "\n",
    "So we have: \n",
    "$x^T \\delta^{(3)} (W^{(2)T}) f'(z^{(2)}) = x^T \\delta^{(2)}$\n",
    "\n",
    "I did not fully understand this part and will return once I have reviewed\n",
    "partial derivatives in the context of the chain rule, as it feels like we're\n",
    "skipping something. In the meantime I will truck onward with neural nets, as ML\n",
    "is a practitioner's art.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic adapted from https://mgarod.medium.com/dynamically-add-a-method-to-a-class-in-python-c49204b85bd6\n",
    "# Makes it more convenient to add as I go in the same notebook\n",
    "def add_method(cls):\n",
    "    def decorator(func):\n",
    "        setattr(cls, func.__name__, func)\n",
    "        return func\n",
    "    return decorator\n",
    "\n",
    "@add_method(Neural_Network)\n",
    "def sigmoidPrime(self, z):\n",
    "  return np.exp(-z) / ((1 + np.exp(-z))**2)\n",
    "\n",
    "@add_method(Neural_Network)\n",
    "def costFunction(self, X, y):\n",
    "    self.y_hat = self.forward(X)\n",
    "    J = sum(0.5 * (y - self.y_hat)**2)\n",
    "    return J\n",
    "\n",
    "@add_method(Neural_Network)\n",
    "def costFunctionPrime(self, X, y):\n",
    "    self.y_hat = self.forward(X)\n",
    "\n",
    "    self.sigPrimeZ3 = self.sigmoidPrime(self.Z3)\n",
    "    self.wrongness = y - self.y_hat\n",
    "\n",
    "    self.delta_3 = np.multiply(-self.wrongness, self.sigPrimeZ3) # element-wise\n",
    "\n",
    "    dJdW2 = np.dot(self.a2.T, self.delta_3)\n",
    "\n",
    "    np.dot(X.T, self.delta_3)\n",
    "\n",
    "    self.sigPrimeZ2 = self.sigmoidPrime(self.Z2)\n",
    "    self.delta_2 = np.dot(self.delta_3, self.W2.T) * self.sigPrimeZ2\n",
    "\n",
    "    dJdW1 = np.dot(X.T, self.delta_2)\n",
    "\n",
    "    return dJdW1, dJdW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does X and y come from? Oh, we're building it a little wonky. I would\n",
    "first run *forward*, then call costFunctionPrime.\n",
    "\n",
    "Why `self.sigmoidPrime(self.Z3)`? Oh, the same as any derivative. If y<sub>hat</sub> is a\n",
    "function of `self.sigmoidPrime(self.Z3)`, then to take the derivative of `y_hat`\n",
    "with respect to `Z3`, we differentiate the underlying function. Which is what we did.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([13.64827723])"
     ]
    }
   ],
   "source": [
    "NN.costFunction(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| array | (((0.13230578 6.74956208 0.26207974) (0.12361459 10.04663462 0.35003568))) | array | (((-0.024160348) (-53.1080763) (-0.0525528428))) |"
     ]
    }
   ],
   "source": [
    "dJdW1, dJdW2 = NN.costFunctionPrime(X, y)\n",
    "dJdW1, dJdW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add the gradient to our weights, we go uphill.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([13.67964497])"
     ]
    }
   ],
   "source": [
    "W1 = NN.W1\n",
    "W2 = NN.W2\n",
    "scalar = 3\n",
    "NN.W1 = NN.W1 + scalar * dJdW1\n",
    "NN.W2 = NN.W2 + scalar * dJdW2\n",
    "cost2 = NN.costFunction(X, y)\n",
    "\n",
    "NN.W1 = W1\n",
    "NN.W2 = W2\n",
    "\n",
    "cost2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we subtract, we go downhill.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "array([13.63838267])"
     ]
    }
   ],
   "source": [
    "W1 = NN.W1\n",
    "W2 = NN.W2\n",
    "scalar = 3\n",
    "NN.W1 = NN.W1 - scalar * dJdW1\n",
    "NN.W2 = NN.W2 - scalar * dJdW2\n",
    "cost3 = NN.costFunction(X, y)\n",
    "\n",
    "# NN.W1 = W1\n",
    "# NN.W2 = W2\n",
    "\n",
    "cost3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? Imagine the cost function, which is a valley, or a bowl. If the gradient is positive, you are on the right side of the valley. If you add, you go uphill. If the gradient is negative, you are on the left side of the valley. If you add a negative number, you move left, that is uphill. In either case we subtract to go downhill.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5, Numerical Gradient Checking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, computers can't do mathematical limits. They can't really do calculus. But\n",
    "that's okay because calculus is all about getting close enough anyway.\n",
    "\n",
    "To check our work, we can simply toggle up and down a little and check that our cost function has improved.\n",
    "\n",
    "We want to add $\\epsilon$ to each weight and compute the cost function, then subtract from each weight and compute the cost function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a helper function to get the weights in a simple format\n",
    "@add_method(Neural_Network)\n",
    "def get_params(self):\n",
    "    params = np.concatenate(( self.W1.ravel(), self.W2.ravel() ))\n",
    "    return params\n",
    "\n",
    "# this is a helper function to set the weights\n",
    "# it works with the getter to roundtrip the weights\n",
    "# it assumes the weights come in as one giant 1D array\n",
    "# then we need to chop up that 1d array at the correct places\n",
    "# np.reshape can run over a 1d array and make rows and cols out of it\n",
    "@add_method(Neural_Network)\n",
    "def setParams(self, params):\n",
    "    W1_start = 0\n",
    "    W1_end = self.hiddenLayersSize * self.inputLayersSize\n",
    "    self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayersSize, self.hiddenLayersSize))\n",
    "    W2_end = W1_end + self.hiddenLayersSize * self.outputLayersSize\n",
    "    self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayersSize, self.outputLayersSize))\n",
    "\n",
    "# a helper function to get our gradients, then flatten them into a 1d array\n",
    "@add_method(Neural_Network)\n",
    "def computeGradients(self, X, y):\n",
    "    dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "    return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n",
    "\n",
    "# This does the hard work of getting the params as a 1d array\n",
    "# then iterating across them all to add and subtract our epsilon\n",
    "@add_method(Neural_Network)\n",
    "def computeNumericalGradient(self, X, y):\n",
    "    paramsInitial = self.get_params()\n",
    "    numgrad = np.zeros(paramsInitial.shape)\n",
    "    perturb = np.zeros(paramsInitial.shape)\n",
    "    e = 1e-4\n",
    "\n",
    "    for p in range(len(paramsInitial)):\n",
    "        #Set perturbation vector: all values in there are now e\n",
    "        perturb[p] = e\n",
    "        self.setParams(paramsInitial + perturb)  # matrix addition, element-wise\n",
    "        loss2 = self.costFunction(X, y)\n",
    "\n",
    "        self.setParams(paramsInitial - perturb)\n",
    "        loss1 = self.costFunction(X, y)\n",
    "\n",
    "        #Compute Numerical Gradient\n",
    "        numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "\n",
    "        #Return Params to original value:\n",
    "        self.setParams(paramsInitial)\n",
    "\n",
    "    return numgrad\n",
    "\n",
    "@add_method(Neural_Network)\n",
    "def checkAccuracy(self):\n",
    "    grad = self.computeGradients(X,y)\n",
    "    numgrad = self.computeNumericalGradient(X, y)\n",
    "    return np.linalg.norm(grad - numgrad) / np.linalg.norm(grad + numgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993355295590062"
     ]
    }
   ],
   "source": [
    "NN.checkAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| array | ((13.59699416)) | array | ((13.59699416)) |"
     ]
    }
   ],
   "source": [
    "@add_method(Neural_Network)\n",
    "def takeScaledStep(self, scalar, X, y):\n",
    "    dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "    self.W1 = self.W1 - scalar * dJdW1\n",
    "    self.W2 = self.W2 - scalar * dJdW2\n",
    "\n",
    "@add_method(Neural_Network)\n",
    "def takeNScaledSteps(self, numSteps, scalar, X, y):\n",
    "    for step in range(numSteps):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "        self.W1 = self.W1 - scalar * dJdW1\n",
    "        self.W2 = self.W2 - scalar * dJdW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above was my attempt at training. It does not work at all, unless the inputs are normalized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100 #Max test score is 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the tutorial implements BFGS. However, I don't understand this portion conceptually, much less the math, and so I will not implement it at this time.\n",
    "\n",
    "I feel that gradient descent should now work. I don't understand why we need to work about further mathematical optimization.\n",
    "\n",
    "It will take the second derivative to get the gradient of the gradient, which provides us more information to move downhill more efficiently.\n",
    "\n",
    "He then uses SciPy's optimize.minimize(), which already implements this function. This is a further strike against this tutorial, as this provides no intuition at all.\n",
    "\n",
    "However, I am very happy that I am able to train this network. It is not very accurate, even with many steps taken! But it improves several orders of magnitude over our original random weights.\n",
    "\n",
    "I understand everything in this and am able to train it. Except for the full partial derivatives math involved in taking the gradient. I am optimistic I will soon fully understand this, as my calculus is returning rapidly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of good notes here. As we have 9 neurons, we would like to have 90 training examples, to reduce overfitting.\n",
    "\n",
    "We could also implement regularization, where we penalize our model for getting overly complex.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization parameter\n",
    "Lambda = 0.0001\n",
    "\n",
    "def costFunction(self, X, y):\n",
    "    self.y_hat = self.forward(X)\n",
    "    J = sum(0.5 * (y - self.y_hat)**2) + Lambda/2 * (sum (self.W1 ** 2) + (self.W2 ** 2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not quite that simple, though. Our model might balance out by weighting one set of weights at the expense of the other.\n",
    "\n",
    "We need to regularize them. To dJdW2 add Lambda \\* self.W2, and to dJdW1 add Lambda \\* self.W2.\n",
    "\n",
    "He also divides by the number of rows in Lambda, the number of examples, I suppose because more examples makes us less likely to overfit and so our cost function should be lower. It is a piece of autoregulation, feedback.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
