{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Part 1, Forward Propagation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We start off by defining some hyperparameters, constants which establish the\nstructure and behavior of the network and are not updated as we train.\n\nWe're going to look at hours of sleep and hours of study, and predict our test score.\n\nHere X is a 3x2 matrix, and Y is 3 x 1.\n\n$3W_{11} + 5W_{21}$ per each neuron is what we want. We need to figure out\nweights for each variable, for each example we have.\n\nWe can do this with matrix multiplication (always remember [http://matrixmultiplication.xyz/](http://matrixmultiplication.xyz/)).\n\n$$  \\begin{bmatrix}\n3 & 5 \\\\\n5 & 1 \\\\\n10 & 2\n\\end{bmatrix} \\begin{bmatrix}\nW_{11} & W_{12} & W_{13}\\\\\nW_{21} & W_{22} & W_{33}\\\\\n\\end{bmatrix}\n$$\n\n$XW^{(1)} = Z^{(2)}$, where $Z^{(2)}$ is the activity of our second layer.\n\n$$\nZ^{(2)} = \\begin{bmatrix}\n3W_{11} + 5W_{21} & 3W_{12} + 5W_{22} & 3W_{13} + 5W_{33} \\\\\n5W_{11} + 1W_{21} & 5W_{12} + 1W_{22} & 5W_{13} + 1W_{33} \\\\\n10W_{11} + 2W_{21} & 10W_{12} + 2W_{22} & 10W_{13} + 2W_{33} \\\\\n\\end{bmatrix}\n$$\n\nSo each entry in Z is a sum of weighted inputs to each neuron. It has size 3x3:\none row for each example, one column for each hidden unit.\n\nNext we will independently apply the activation function to each entry in Z.\nWe'll use the sigmoid function, leaning on NumPy, which rather conveniently\napplies the function element-wise and returns the result with the same\ndimensions it was given.\n\n$$\na^{(2)} = \\begin{bmatrix}\n\\sigma(3W_{11} + 5W_{21}) & \\sigma(3W_{12} + 5W_{22}) & \\sigma(3W_{13} + 5W_{33}) \\\\\n\\sigma(5W_{11} + 1W_{21}) & \\sigma(5W_{12} + 1W_{22}) & \\sigma(5W_{13} + 1W_{33}) \\\\\n\\sigma(10W_{11} + 2W_{21}) & \\sigma(10W_{12} + 2W_{22}) & \\sigma(10W_{13} + 2W_{33}) \\\\\n\\end{bmatrix}\n$$\n\nSo we have $a^{(2)} = f(Z^{(2)})$. We'll then apply one more set of weights to\nget our final output, with dimensions 3 x 1, and then run the activation function on that too.\n\n$Z^{(3)} = a^{(2)} W^{(2)}$, and $\\hat{y} = f(Z^{(3)})$\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"| 75 | 82 | 93 |"}],"source":["X = [[3, 5], \n     [5, 1], \n     [10, 2]]\ny = [75, 82, 93]\ny"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"array([[0.67139173],\n       [0.6694768 ],\n       [0.65219914]])"}],"source":["import numpy as np\ndef sigmoid(z):\n    return 1/(1 + np.exp(-z))\n\nclass Neural_Network(object):\n    def __init__(self):\n        self.inputLayersSize = 2\n        self.outputLayersSize = 1\n        self.hiddenLayersSize = 3\n\n        self.W1 = np.random.randn(self.inputLayersSize, self.hiddenLayersSize)\n        self.W2 = np.random.randn(self.hiddenLayersSize, self.outputLayersSize)\n\n    def forward(self, X):\n        Z2 = np.dot(X, self.W1)\n        a2 = self.sigmoid(Z2)\n\n        Z3 = np.dot(a2, self.W2)\n\n        y_hat = self.sigmoid(Z3)\n\n        return y_hat\n        \n    def sigmoid(self, z):\n        return 1/(1 + np.exp(-z))\n\nsigmoid(1), sigmoid(np.array([-1, 0, 1])), sigmoid(np.random.randn(3, 3))\n\nNN = Neural_Network()\ny_hat = NN.forward(X)\ny_hat"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, these results are completely terrible compared to our actual test\nscores! That is because we are using random weights. Next we need to update our weights.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Part 3, Back Propagation Theory\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Our goal now is to quantify how wrong our predictions are, figure out how to\nupdate our weights in the right direction, and use our wrongess-quantity to\nadjust the weights by some suitable amount.\n\nWe could use several measures of wrongness. For instance, we could just take\n$y - \\hat{y}$, and that would be fine. Because we're coming up with a single\nweight for all our examples, we would average this. Our loss function would thus\nbe Mean Absolute Error, or MAE.\n\nHowever, Mean Squared Error is more commonly used, although\n[arguments for this are not perfectly convincing](https://stats.stackexchange.com/questions/470626/why-is-using-squared-error-the-standard-when-absolute-error-is-more-relevant-to). It is a little easier to do\ncalculus on, and most importantly, because it is a convex function, we can be\nsure it will be defined at 0, and more extreme errors will get penalized more,\nmeaning we will learn faster the wronger we are, which is nice.\n\nMean Squared Error looks like $\\sum (y - \\hat{y})^2$, and if we divide by 2 to\nhelp us do calculus later it will still have all the properties we want: $J = \\sum \\frac{1}{2}\n(y - \\hat{y})^2$.\n\nNow that we have a loss function, how do we know how to improve our weights?\nRandom guessing will not work, due to the curse of dimensionality. With 6\nweights, assume they might have 1000 possible values each, and we have\n$1000^{6}$ guesses to make!\n\nWe could also jiggle each weight up or down a little, and see if the whole thing\nimproves. That will work but be slow.\n\nFortunately we have a better way! We want to know how our cost function J\nchanges when $\\hat{y}$, or W, changes. This is a derivative! If the derivative\nis positive, we are heading in the wrong direction. We'll keep changing until\nthe derivative of our loss function starts getting worse again.\n\nIf we consider one weight at a time, then we want to know how J changes when\njust one weight changes, and that's a partial derivative: $\\frac{\\partial\nJ}{\\partial W}$.\n\nThis is one reason we chose our loss function as we did. It's convex, so we will\nalways know which direction to go in. In higher dimensions, the combination of\nall these weights could get us stuck in a local minimum, but if we update our\nweights one at a time (stochastic gradient descent), we might be fine anyway.\n\nAnyway, today we will do batch gradient descent, and update them all at once,\nbased on the partial derivative of each.\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}