{"cells":[{"cell_type":"markdown","metadata":{},"source":["## The net\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](./images/net.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Part 1, Forward Propagation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We start off by defining some hyperparameters, constants which establish the\nstructure and behavior of the network and are not updated as we train.\n\nWe're going to look at hours of sleep and hours of study, and predict our test score.\n\nHere X is a 3x2 matrix, and Y is 3 x 1.\n\n$3W_{11} + 5W_{21}$ per each neuron is what we want. We need to figure out\nweights for each variable, for each example we have.\n\nWe can do this with matrix multiplication (always remember [http://matrixmultiplication.xyz/](http://matrixmultiplication.xyz/)).\n\n$$  \\begin{bmatrix}\n3 & 5 \\\\\n5 & 1 \\\\\n10 & 2\n\\end{bmatrix} \\begin{bmatrix}\nW_{11} & W_{12} & W_{13}\\\\\nW_{21} & W_{22} & W_{23}\\\\\n\\end{bmatrix}\n$$\n\n$XW^{(1)} = Z^{(2)}$, where $Z^{(2)}$ is the activity of our second layer.\n\n$$\nZ^{(2)} = \\begin{bmatrix}\n3W_{11} + 5W_{21} & 3W_{12} + 5W_{22} & 3W_{13} + 5W_{33} \\\\\n5W_{11} + 1W_{21} & 5W_{12} + 1W_{22} & 5W_{13} + 1W_{33} \\\\\n10W_{11} + 2W_{21} & 10W_{12} + 2W_{22} & 10W_{13} + 2W_{33} \\\\\n\\end{bmatrix}\n$$\n\nSo each entry in Z is a sum of weighted inputs to each neuron. It has size 3x3:\none row for each example, one column for each hidden unit.\n\nNext we will independently apply the activation function to each entry in Z.\nWe'll use the sigmoid function, leaning on NumPy, which rather conveniently\napplies the function element-wise and returns the result with the same\ndimensions it was given.\n\n$$\na^{(2)} = \\begin{bmatrix}\n\\sigma(3W_{11} + 5W_{21}) & \\sigma(3W_{12} + 5W_{22}) & \\sigma(3W_{13} + 5W_{33}) \\\\\n\\sigma(5W_{11} + 1W_{21}) & \\sigma(5W_{12} + 1W_{22}) & \\sigma(5W_{13} + 1W_{33}) \\\\\n\\sigma(10W_{11} + 2W_{21}) & \\sigma(10W_{12} + 2W_{22}) & \\sigma(10W_{13} + 2W_{33}) \\\\\n\\end{bmatrix}\n$$\n\nSo we have $a^{(2)} = f(Z^{(2)})$. We'll then apply one more set of weights to\nget our final output, with dimensions 3 x 1, and then run the activation function on that too.\n\n$Z^{(3)} = a^{(2)} W^{(2)}$, and $\\hat{y} = f(Z^{(3)})$\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"array([[75],\n       [82],\n       [93]])"}],"source":["import numpy as np\nX = np.array([[3, 5],\n             [5, 1],\n             [10, 2]])\ny = np.array([[75], [82], [93]])"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def sigmoid(z):\n    return 1/(1 + np.exp(-z))\n\nclass Neural_Network(object):\n    def __init__(self):\n        self.inputLayersSize = 2\n        self.outputLayersSize = 1\n        self.hiddenLayersSize = 3\n\n        self.W1 = np.random.randn(self.inputLayersSize, self.hiddenLayersSize)\n        self.W2 = np.random.randn(self.hiddenLayersSize, self.outputLayersSize)\n\n    def forward(self, X):\n        self.Z2 = np.dot(X, self.W1)\n        self.a2 = self.sigmoid(self.Z2)\n\n        self.Z3 = np.dot(self.a2, self.W2)\n\n        y_hat = self.sigmoid(self.Z3)\n\n        return y_hat\n\n    def sigmoid(self, z):\n        return 1/(1 + np.exp(-z))"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"array([[0.09039106],\n       [0.06463066],\n       [0.06301298]])"}],"source":["sigmoid(1), sigmoid(np.array([-1, 0, 1])), sigmoid(np.random.randn(3, 3))\n\nNN = Neural_Network()\ny_hat = NN.forward(X)\ny_hat"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, these results are completely terrible compared to our actual test\nscores! That is because we are using random weights. Next we need to update our weights.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Parts 2 - 4: Gradient Descent and Back Propagation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Our goal now is to quantify how wrong our predictions are, figure out how to\nupdate our weights in the right direction, and use our wrongess-quantity to\nadjust the weights by some suitable amount.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Quantifying wrongness with a loss function\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We could use several measures of wrongness. For instance, we could just take\n$y - \\hat{y}$, and that would be fine. Because we're coming up with a single\nweight for all our examples, we would average this. Our loss function would thus\nbe Mean Absolute Error, or MAE.\n\nHowever, Mean Squared Error is more commonly used, although\n[arguments for this are not perfectly convincing](https://stats.stackexchange.com/questions/470626/why-is-using-squared-error-the-standard-when-absolute-error-is-more-relevant-to). It is a little easier to do\ncalculus on, and most importantly, because it is a convex function, we can be\nsure it will be defined at 0, and more extreme errors will get penalized more,\nmeaning we will learn faster the wronger we are, which is nice.\n\nMean Squared Error looks like $\\sum (y - \\hat{y})^2$, and if we divide by 2 to\nhelp us do calculus later it will still have all the properties we want: $J = \\sum \\frac{1}{2}\n(y - \\hat{y})^2$.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Which way to jiggle the weights\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Now that we have a loss function, how do we know how to improve our weights?\nRandom guessing will not work, due to the curse of dimensionality. With 6\nweights, assume they might have 1000 possible values each, and we have\n$1000^{6}$ guesses to make!\n\nWe could also jiggle each weight up or down a little, and see if the whole thing\nimproves. That will work but be slow.\n\nFortunately we have a better way! We want to know how our cost function J\nchanges when $\\hat{y}$, or W, changes. This is a derivative! If the derivative\nis positive, we are heading in the wrong direction. We'll keep changing until\nthe derivative of our loss function starts getting worse again.\n\nIf we consider one weight at a time, then we want to know how J changes when\njust one weight changes, and that's a partial derivative: $\\frac{\\partial\nJ}{\\partial W}$.\n\nThis is one reason we chose our loss function as we did. It's convex, so we will\nalways know which direction to go in. In higher dimensions, the combination of\nall these weights could get us stuck in a local minimum, but if we update our\nweights one at a time (stochastic gradient descent), we might be fine anyway.\n\nAnyway, today we will do batch gradient descent, and update them all at once,\nbased on the partial derivative of each.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Doing the Math\n\n"]},{"cell_type":"markdown","metadata":{},"source":["For $W^{(1)}$ we should get:\n\n\\begin{bmatrix}\n\\frac{\\partial J}{\\partial W_{11}} & \\frac{\\partial J}{\\partial W_{12}} & \\frac{\\partial J}{\\partial W_{13}}\\\\\n\\frac{\\partial J}{\\partial W_{21}} & \\frac{\\partial J}{\\partial W_{22}} & \\frac{\\partial J}{\\partial W_{33}}\\\\\n\\end{bmatrix}\n\nAnd for $W^{(2)}$ we should get:\n\n\\begin{bmatrix}\n\\frac{\\partial J}{\\partial W_{11}^{(2)}} \\\\\n\\frac{\\partial J}{\\partial W_{21}^{(2)}} \\\\\n\\frac{\\partial J}{\\partial W_{31}^{(2)}}\n\\end{bmatrix}\n\n$\\frac{\\partial J}{\\partial W^{(2)}} = \\frac{\\partial \\sum \\frac{1}{2} (y -\n\\hat{y})^2}{\\partial W^{(2)}}$, since that's what J is.\n\nThe sum here is adding the error from each example to create an overall cost.\nThe Sum Rule, $\\frac{d}{dx}(u + v) = \\frac{du}{dx} + \\frac{dv}{dx}$, says that\nwe can move the summation outside our derivative, which is handy.\n\n$\\sum \\frac{\\partial \\frac{1}{2} (y - \\hat{y})^2}{\\partial W^{(2)}}$\n\nWe'll come back and add up later.\n\nWell, next we apply the power rule: $\\frac{\\partial J}{\\partial W^{(2)}} = 2\n\\cdot \\frac{1}{2} (y - \\hat{y})} = (y - \\hat{y})$, and isn't that convenient.\n\nThat was the outer function, now to follow the chain rule we must take the\nderivative of the inner function.\n\nA better name for back propagation might be, don't stop doing the chain rule, ever!\n\nThe $y$ is a constant and goes to 0.\n\n$\\frac{\\partial J}{\\partial W^{(2)}} = (y - \\hat{y}) \\cdot - \\frac{\\partial \\hat{y}}{\\partial W^{(2)}}$\n\nHowever $\\hat{y}$ is itself a function, $\\hat{y} = f(z^{(3)})$, and we must apply the chain rule again.\n\n$\\frac{\\partial \\hat{y}}{\\partial W^{(2)}} = \\frac{\\partial \\hat{y}}{\\partial z^{(3)}} \\cdot \\frac{\\partial z^{(3)}}{\\partial W^{(2)}}$\n\nMeaning, again, we want the entire phrase:  \n$- (y - \\hat{y}) \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(3)}} \\cdot \\frac{\\partial z^{(3)}}{\\partial W^{(2)}}$\n\nNow, $f(z^{(3)})$ was our sigmoid function, which is $\\frac{1}{1 + e^{-z}}$.\n\nTo take this derivative, rewrite as $(1 + e^{-z})^{-1}$, and apply the power\nrule to get $-(1 + e^{-z})^{-2}$, but then we must apply the product rule to get\n$-(1 + e^{-z})^{-2})(\\frac{d}{z} 1 + e^{-z})$. Which equals:\n\n$-(1 + e^{-z})^{-2})(\\frac{d}{dz}(1 + e^{-z})) = -(1 + e^{-z})^{-2})(-1)(e^{-z}))$\n\nAnd:\n$\\frac{e^{-z}}{(1 + e^{-z})^{2}}$. If you do a lot of algebra there, you can\nalso write this as $\\sigma(x) \\cdot (1 - \\sigma(x))$.\n\nHaving found $f'(z^{(3)}$, we can slot that in.\n\n$- (y - \\hat{y}) \\cdot \\frac{e^{-z}}{(1 + e^{-z})^{2}} \\cdot \\frac{\\partial z^{(3)}}{\\partial W^{(2)}}$\n\nAnd we just need our last term. This is how our output - the sum of the\nactivated (first weights \\* inputs) multiplied by the second weights - changes as\nthe second weights change.\n\nHere's the thing, z3 is a linear function with respect to the W2 weights. Their\nrelationship is measured by the activations. If\nthey go up, the values go up. And the derivative of a linear function - it's\njust a plain ol' slope like we learned in 5th grade. Here the slope is the\nactivations, a2.\n\n(this doesn't sound right to me. We change the weights W2, surely)\n\nOur final formula:\n\n$- (y - \\hat{y}) \\cdot \\frac{e^{-z}}{(1 + e^{-z})^{2}} \\cdot a^{(2)}$\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Zoom Out a Bit\n\n"]},{"cell_type":"markdown","metadata":{},"source":["All that calculus! We wanted to figure out how much our output depended on the\nfinal set of weights we applied. First we had to apply the power rule. Then, we\nfigured out how much our output was changed by our sigmoid function. Then we\nmultiplied by the activations.\n\nRemember we'll calculate all this by neuron, by weight. You can think about this\nas: we multiply by each activation, because that is how much they each\nproportionately contributed to the error. Crucially, this is what lets back\npropagation work its magic!\n\n**Our final formula in a nutshell**: *Multiply the size of error, by the derivative of the activation\nfunction, by all our examples with the weights and activation function applied.* \n\nIf you do all that, you will know just how to change each weight.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Multiply it out\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### The errors\n\n"]},{"cell_type":"markdown","metadata":{},"source":["$$  \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\ny_3 \\\\\n\\end{bmatrix} - \\begin{bmatrix}\n\\hat{y}_1 \\\\\n\\hat{y}_2 \\\\\n\\hat{y}_3 \\\\\n\\end{bmatrix} = \\begin{bmatrix}\ny_1 - \\hat{y}_1 \\\\\ny_2 - \\hat{y}_2 \\\\\ny_3 - \\hat{y}_3 \\\\\n\\end{bmatrix}\n$$\n\nWhen we applied sigmoid function, we also got a 3x1 matrix, and sigmoidPrime\nwill have the same shape. In other words $f'(z^{(3)}$ is also 3x1, and we can do\nelement-wise multiplication.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["fakeYs = [[1], [2], [3]]\nfakeSigPrime = [[1], [2], [3]]\n\nnp.multiply(fakeYs, fakeSigPrime)"]},{"cell_type":"markdown","metadata":{},"source":["#### The size of each error\n\n"]},{"cell_type":"markdown","metadata":{},"source":["$$\n\\begin{bmatrix}\ny_1 - \\hat{y}_1 \\\\\ny_2 - \\hat{y}_2 \\\\\ny_3 - \\hat{y}_3 \\\\\n\\end{bmatrix} \\begin{bmatrix}\nf'(z^{(3)}_1) \\\\\nf'(z^{(3)}_2) \\\\\nf'(z^{(3)}_3) \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n\\delta^{(3)}_1 \\\\\n\\delta^{(3)}_2 \\\\\n\\delta^{(3)}_3 \\\\\n\\end{bmatrix} = \\delta^{(3)}\n$$\n\nThis is called \"the back-propagating error, $\\delta^{(3)}$.\"\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Multiply together\n\n"]},{"cell_type":"markdown","metadata":{},"source":["At this point we want to multiply by $a^{(2)}$, $\\delta^{(3)} a^{(2)}$. However,\nwe've got\n\n$$ a^{(2)} = \\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\\\\\n\\end{bmatrix}\n$$\n\nThese matrices don't match. You can't multiply 3x1 with 3x3.\n\nWe can make it work by transposing and multiplying, which I'll assume is the\nsame thing in linear algebra, or something. You can multiply 3x3 with 3x1.\n\n\\\\[\n\n\\begin{bmatrix}\na_{11} & a_{21} & a_{31}\\\\\na_{12} & a_{22} & a_{32}\\\\\na_{13} & a_{23} & a_{33}\\\\\n\\end{bmatrix} \\begin{bmatrix}\n\\delta^{(3)}_1 \\\\\n\\delta^{(3)}_2 \\\\\n\\delta^{(3)}_3 \\\\\n\\end{bmatrix} = \\begin{bmatrix}\na_{11} \\: \\delta^{(3)}_1 + a_{21} \\: \\delta^{(3)}_2 + a_{31} \\: \\delta^{(3)}_3 \\\\\na_{12} \\: \\delta^{(3)}_1 + a_{22} \\: \\delta^{(3)}_2 + a_{32} \\: \\delta^{(3)}_3 \\\\\na_{13} \\: \\delta^{(3)}_1 + a_{23} \\: \\delta^{(3)}_2 + a_{33} \\: \\delta^{(3)}_3 \\\\\n\\end{bmatrix} \n\n\\\\]\n\nAnd the cool thing here is that the matrix multiplication is adding up across\nour examples - there's that summation $\\Delta$ we took out earlier!\n\nYou can also think of batching gradient as contributing to the overall cost.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Once More, with Feeling\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Now that we have propagated the error backward to our last set of weights, we\nneed to keep going. How did our first set of weights affect the output? We will\ndo the same thing, take the partial differential with respect to those weights.\n\n$\\frac{\\partial J}{\\partial W^{(1)}} = \\frac{\\partial \\sum \\frac{1}{2} (y -\n\\hat{y})^2}{\\partial W^{(1)}}$, since that's what J is.\n\nMove the summation outside: \n$\\sum \\frac{\\partial \\frac{1}{2} (y - \\hat{y})^2}{\\partial W^{(1)}}$\n\nThen $- (y - \\hat{y}) \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(3)}} \\cdot \\frac{\\partial z^{(3)}}{\\partial W^{(1)}}$\n\nRemember that $- (y - \\hat{y}) \\cdot \\frac{\\partial \\hat{y}}{\\partial z^{(3)}}$\ntranslates to the back-propagating error, $\\delta^{(3)}$.\n\nNow we are\ncalculating the rate of change of z3 with respec to a2, $$\\frac{dz}{da_2}$$, so\nto speak. The slope here equals the weight value for that synapse.\n\nFor some reason he says last time we computed the derivative with respect to the\nweights but now we are computing across the synapses.\n\n$\\delta^{(3)} \\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\frac{\\partial\na^{(2)}}{\\partial W^{(1)}}$\n\nThe slope is now equal to the weight value for this synapse, which frankly makes\nmore sense than the a2 being the slope as it was last time.\n\nWe'll achieve this by multiplying by the transpose:\n\n$\\delta^{(3)} (W^{(2)}^T) \\frac{\\partial a^{(2)}}{\\partial W^{(1)}}$\n\nthe last term separates into $\\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\frac{\\partial z^{(2)}}{\\partial W^{(1)}}$\n\nThe first part is the whole sigmoid calculation we did before and so we replace\nwith $f'(z^{(2)})$.\n\nThe second part works out as it did last time with $a^{(2)}$, but with X this time.\n\nSo we have: \n$x^T \\delta^{(3)} (W^{(2)T}) f'(z^{(2)}) = x^T \\delta^{(2)}$\n\nI did not fully understand this part and will return once I have reviewed\npartial derivatives in the context of the chain rule, as it feels like we're\nskipping something. In the meantime I will truck onward with neural nets, as ML\nis a practitioner's art.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Part 4\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Magic adapted from https://mgarod.medium.com/dynamically-add-a-method-to-a-class-in-python-c49204b85bd6\n# Makes it more convenient to add as I go in the same notebook\ndef add_method(cls):\n    def decorator(func):\n        setattr(cls, func.__name__, func)\n        return func\n    return decorator\n\n@add_method(Neural_Network)\ndef sigmoidPrime(self, z):\n  return np.exp(-z) / ((1 + np.exp(-z))**2)\n\n@add_method(Neural_Network)\ndef costFunction(self, X, y):\n    self.y_hat = self.forward(X)\n    J = sum(0.5 * (y - self.y_hat)**0.5)\n    return J\n\n@add_method(Neural_Network)\ndef costFunctionPrime(self, X, y):\n    self.y_hat = self.forward(X)\n\n    self.sigPrimeZ3 = self.sigmoidPrime(self.Z3)\n    self.wrongness = y - self.y_hat\n\n    self.delta_3 = np.multiply(-self.wrongness, self.sigPrimeZ3) # element-wise\n\n    dJdW2 = np.dot(self.a2.T, self.delta_3)\n\n    np.dot(X.T, self.delta_3)\n\n    self.sigPrimeZ2 = self.sigmoidPrime(self.Z2)\n    self.delta_2 = np.dot(self.delta_3, self.W2.T) * self.sigPrimeZ2\n\n    dJdW1 = np.dot(X.T, self.delta_2)\n\n    return dJdW1, dJdW2"]},{"cell_type":"markdown","metadata":{},"source":["Where does X and y come from? Oh, we're building it a little wonky. I would\nfirst run *forward*, then call costFunctionPrime.\n\nWhy `self.sigmoidPrime(self.Z3)`? Oh, the same as any derivative. If y<sub>hat</sub> is a\nfunction of `self.sigmoidPrime(self.Z3)`, then to take the derivative of `y_hat`\nwith respect to `Z3`, we differentiate the underlying function. Which is what we did.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Updating\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"array([13.64827723])"}],"source":["NN.costFunction(X, y)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"| array | (((0.13230578 6.74956208 0.26207974) (0.12361459 10.04663462 0.35003568))) | array | (((-0.024160348) (-53.1080763) (-0.0525528428))) |"}],"source":["dJdW1, dJdW2 = NN.costFunctionPrime(X, y)\ndJdW1, dJdW2"]},{"cell_type":"markdown","metadata":{},"source":["If we add the gradient to our weights, we go uphill.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"array([13.67964497])"}],"source":["W1 = NN.W1\nW2 = NN.W2\nscalar = 3\nNN.W1 = NN.W1 + scalar * dJdW1\nNN.W2 = NN.W2 + scalar * dJdW2\ncost2 = NN.costFunction(X, y)\n\nNN.W1 = W1\nNN.W2 = W2\n\ncost2"]},{"cell_type":"markdown","metadata":{},"source":["If we subtract, we go downhill.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\narray([13.63838267])"}],"source":["W1 = NN.W1\nW2 = NN.W2\nscalar = 3\nNN.W1 = NN.W1 - scalar * dJdW1\nNN.W2 = NN.W2 - scalar * dJdW2\ncost3 = NN.costFunction(X, y)\n\n# NN.W1 = W1\n# NN.W2 = W2\n\ncost3"]},{"cell_type":"markdown","metadata":{},"source":["## Part 5, Numerical Gradient Checking\n\n"]},{"cell_type":"markdown","metadata":{},"source":["So, computers can't do mathematical limits. They can't really do calculus. But\nthat's okay because calculus is all about getting close enough anyway.\n\nTo check our work, we can simply toggle up and down a little and check that our cost function has improved.\n\nWe want to add $\\epsilon$ to each weight and compute the cost function, then subtract from each weight and compute the cost function.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# this is a helper function to get the weights in a simple format\n@add_method(Neural_Network)\ndef get_params(self):\n    params = np.concatenate(( self.W1.ravel(), self.W2.ravel() ))\n    return params\n\n# this is a helper function to set the weights\n# it works with the getter to roundtrip the weights\n# it assumes the weights come in as one giant 1D array\n# then we need to chop up that 1d array at the correct places\n# np.reshape can run over a 1d array and make rows and cols out of it\n@add_method(Neural_Network)\ndef setParams(self, params):\n    W1_start = 0\n    W1_end = self.hiddenLayersSize * self.inputLayersSize\n    self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayersSize, self.hiddenLayersSize))\n    W2_end = W1_end + self.hiddenLayersSize * self.outputLayersSize\n    self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayersSize, self.outputLayersSize))\n\n# a helper function to get our gradients, then flatten them into a 1d array\n@add_method(Neural_Network)\ndef computeGradients(self, X, y):\n    dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n    return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n\n# This does the hard work of getting the params as a 1d array\n# then iterating across them all to add and subtract our epsilon\n@add_method(Neural_Network)\ndef computeNumericalGradient(self, X, y):\n    paramsInitial = self.get_params()\n    numgrad = np.zeros(paramsInitial.shape)\n    perturb = np.zeros(paramsInitial.shape)\n    e = 1e-4\n\n    for p in range(len(paramsInitial)):\n        #Set perturbation vector: all values in there are now e\n        perturb[p] = e\n        self.setParams(paramsInitial + perturb)  # matrix addition, element-wise\n        loss2 = self.costFunction(X, y)\n\n        self.setParams(paramsInitial - perturb)\n        loss1 = self.costFunction(X, y)\n\n        #Compute Numerical Gradient\n        numgrad[p] = (loss2 - loss1) / (2*e)\n\n        #Return the value we changed to zero:\n        perturb[p] = 0  # this seems unnecessary though.\n        \n        #Return Params to original value:\n        self.setParams(paramsInitial)\n\n    return numgrad\n\n@add_method(Neural_Network)\ndef checkAccuracy(self):\n    grad = self.computeGradients(X,y)\n    numgrad = self.computeNumericalGradient(X, y)\n    return np.linalg.norm(grad - numgrad) / np.linalg.norm(grad + numgrad)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.9993355295590062"}],"source":["NN.checkAccuracy()"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}